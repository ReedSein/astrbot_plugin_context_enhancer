# Context Enhancer 插件

## 简介

Context Enhancer 是一个为大语言模型（LLM）设计的上下文预处理器与增强器。它将原生、复杂的多模态消息，转换为 LLM 易于理解和使用的高质量、纯文本对话历史与结构化信息。

## 核心功能

*   **丰富的上下文收集**：自动收集群聊中的历史消息、机器人的历史回复，构建完整的对话链条。
*   **🚀 多模态支持**：能够提取历史消息中的图片，并将其 URL 直接提供给支持多模态输入的 LLM（如 GPT-4o, Gemini），让机器人真正“看懂”图片内容。
*   **🧠 智能场景判断**：通过内部机制精确区分“被动回复”（用户@机器人或使用命令）与“主动发言”（由其他插件唤醒），并应用不同的对话策略，使回复更贴切、自然。
*   **🛡️ 向后兼容**：能够安全、平滑地加载由旧版插件生成的缓存文件，确保升级过程无缝衔接。
*   **🧩 高扩展性**：在消息对象中完整保留了原始消息组件 (`raw_components`)，为未来处理更复杂消息格式（如表情、文件等）的功能扩展提供了坚实基础。
*   **🖼️ 图片描述（可选）**：可配置调用具备图像分析能力的模型，将历史图片转换为文字描述并注入文本上下文，作为多模态支持的补充。

## 工作流程

插件通过一个三步流程，将原始消息事件转化为对 LLM 友好的输入：

1.  **捕获与转换 (Capture & Transform)**：插件监听平台原生的消息事件，将消息体中的多维组件（如图片、表情符号、引用回复）“文本化”，并提取图片资源的有效 URL。

2.  **分析与增强 (Analyze & Enrich)**：插件分析消息的触发方式（如被动提及、主动命令），并为其附加额外的语义元数据，例如标识对话场景的 `message_type` 和用于请求追踪的 `nonce`。

3.  **注入与提供 (Inject & Provide)**：在向 LLM 发起请求的阶段，插件将预处理完成的纯文本对话历史以及提取的图片 URL 列表，动态注入到最终的请求体中，供模型使用。

## 核心优势

相较于 AstrBot 原生的消息处理机制，本插件提供了显著的优化。原生 `AstrMessageEvent` 虽然保留了完整的事件信息，但其复杂的对象结构和非文本组件不适合直接作为 LLM 的输入。本插件的优势在于：

*   **对 LLM 友好 (LLM-Friendly)**：将复杂的多维消息结构**扁平化**为 LLM 最易于理解的纯文本格式，消除了模型处理结构化数据的负担。

*   **多模态能力 (Multimodal Ready)**：将原生消息中无法直接处理的图片对象，**转换为可用的 URL 列表**，从而解锁并赋能 LLM 的多模态视觉理解能力。

*   **语义化上下文 (Semantic Context)**：通过注入 `message_type` 等关键元数据，使 LLM 能够**精准区分不同的对话场景**（例如，是被动聊天还是在执行命令），从而做出更智能、更贴切的响应。

*   **解耦与持久化 (Decoupled & Persistent)**：采用独立的 `GroupMessage` 数据结构来存储上下文，实现了与框架底层事件的解耦。这不仅使上下文的**缓存和跨会话持久化**成为可能，也增强了系统的模块化和可维护性。


## 配置说明

插件的所有配置项都可以在 `config/plugin_config.yaml` 中进行修改。

| 配置项名称 | 类型 | 描述 | 默认值 |
| :--- | :--- | :--- | :--- |
| `enabled_groups` | `list` | 启用插件的群组ID列表。空列表表示对所有群生效。 | `[]` |
| `recent_chats_count` | `int` | 上下文中包含的最近聊天记录数量。 | `15` |
| `bot_replies_count` | `int` | 上下文中包含的机器人自身历史回复数量。 | `5` |
| `collect_bot_replies` | `bool` | 是否收集机器人自身的回复，以构建更完整的对话历史。 | `true` |
| **`max_images_in_context`** | `int` | **（新）** 向LLM请求时，上下文中最多包含的图片URL数量。 | `4` |
| `enable_image_caption` | `bool` | 是否为图片生成描述文本。开启后会调用LLM进行图片转述，作为文本上下文的一部分。 | `true` |
| `image_caption_provider_id` | `string` | 用于图片描述的专用LLM提供商ID。为空则使用主提供商。 | `""` |
| `image_caption_prompt` | `string` | 生成图片描述时使用的提示词模板。 | `"请简洁地描述这张图片的主要内容，重点关注与聊天相关的信息"` |
| `image_caption_timeout` | `int` | 调用LLM进行图片描述时的超时时间（秒）。 | `30` |
| `inactive_cleanup_days` | `int` | 一个群组如果连续N天没有消息，将自动清理其上下文缓存以节省内存。 | `7` |
| `cleanup_interval_seconds` | `int` | 每隔多少秒检查一次是否有不活跃的群组需要清理。 | `600` |
| `command_prefixes` | `list` | 当消息以此列表中的任何前缀开头时，将被视为直接触发LLM的命令。 | `["/", "!", "！", "#", ".", "。"]` |
| `duplicate_check_window_messages` | `int` | 在判断新消息是否重复时，向前追溯检查的消息数量。 | `5` |
| `duplicate_check_time_seconds` | `int` | 在判断新消息是否重复时，两条消息时间戳在此秒数内才被视为可能重复。 | `30` |
| `passive_reply_instruction` | `string` | **核心指令**：当用户@机器人或使用命令时，附加在上下文末尾的指令。变量: `{sender_name}`, `{sender_id}`, `{original_prompt}` | `"现在，群成员 {sender_name} (ID: {sender_id}) 正在对你说话，或者提到了你，TA说：\"{original_prompt}\"\n你需要根据以上聊天记录和你的角色设定，直接回复该用户。"` |
| `active_speech_instruction` | `string` | **核心指令**：当机器人决定主动发言时（如被其他插件触发），附加在上下文末尾的指令。变量: `{original_prompt}` | `"以上是最近的聊天记录。现在，你决定主动参与讨论，并想就以下内容发表你的看法：\"{original_prompt}\"\n你需要根据以上聊天记录和你的角色设定，自然地切入对话。"` |
## 使用示例/场景

**场景：群友发送图片并提问**

1.  **用户A** 在群里发送了一张包含一只橘猫的图片。
2.  **用户B** 接着问：“@机器人 这是什么品种的猫？”
3.  **插件工作流程**：
    *   `context_enhancer` 插件收集到了用户A发送的图片和用户B的提问。
    *   当机器人被@时，插件触发 `on_llm_request`。
    *   它将历史聊天记录（包括用户B的提问）和**图片URL**打包，一起发送给多模态LLM。
4.  **机器人回复**：“根据图片来看，这很可能是一只中华田园猫，通常我们称之为‘大橘’。它的毛色非常经典！”


通过这种方式，机器人能够直接理解图片内容并结合问题进行回答，实现了真正意义上的多模态对话。
