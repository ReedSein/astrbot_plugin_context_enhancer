# `astrbot_plugin_context_enhancer` 插件功能详解 (增强版)

## 🎯 核心目标

一句话概括：**让你的 Bot 能“联系上下文”说话，像个真正参与群聊的人一样，而不是一个只会一问一答的机器。**

它通过在 LLM（大语言模型）处理任何请求前，悄悄地塞给 AI 一段“前情提要”，帮助 AI 理解“刚才发生了什么”，从而做出更智能、更自然的回复。

---

## ⚙️ 它是如何工作的？(增强后的工作流程)

这个插件像一个信息收集员和情报分析师，默默地做了三件精准而高效的事情：

### 1. **信息收集：时刻监听群聊**

-   **监听所有消息**: 插件会监听你在指定群聊里发的每一条消息，无论是普通聊天、发的图片，还是与机器人相关的消息。
-   **分类存储**: 它会将这些消息分门别类地存放在一个临时的“记忆”里（每个群分开存放）。
-   **记录自己的话**: 当机器人回复了你之后，它会通过**精确的ID比对** (`event.get_self_id()`) 来识别出“自己说过的话”并记下来，确保记录的准确性。

### 2. **情报分析与注入：在每次LLM请求时自动增强**

-   **全局增强**: 插件的核心功能现在挂载在**所有LLM请求**上。这意味着，无论是**用户@机器人**触发的被动回复，还是**其他插件（如定时任务）**发起的`主动回复`，只要需要调用LLM，本插件就会自动为其增强上下文。
-   **智能场景识别**: 插件会自动检测请求的来源：
    -   **用户触发**: 如果请求是由一个明确的用户消息发起的，它会构建包含该用户信息的上下文，例如：“现在 张三 发了一个消息...”。
    -   **主动触发**: 如果请求是系统或另一个插件主动发起的（没有明确的用户），它会使用更符合主动发言逻辑的上下文，例如：“你需要主动就以下内容发表观点...”。
-   **整理材料**: 在识别场景后，它会立刻从“记忆”里，把最近的几条信息拿出来，整理成一份简洁的报告，包含：
    1.  **最近的聊天记录**: 挑选出最近的几条普通聊天内容和图片信息。
    2.  **机器人最近的回复**: 附上机器人自己最近说过的几句话。
-   **拼接发送**: 最后，插件会将这份“前情提要”和你当前的问题拼接在一起，形成一个更长的、信息更丰富的“超级问题”，再发送给LLM。

### ✨ 这个增强有什么优势？

这种全局增强机制，使得本插件成为了一个**上下文中心**。任何其他插件，无论功能多么简单，只要它通过标准流程调用LLM，它的回复就能自动获得“读空气”的能力，而无需为它自己编写任何上下文管理代码。

---

## 📤 最终输出是什么？(两个场景示例)

#### 场景一：用户被动触发 (同之前)

1.  **张三**: "今天天气真好啊，阳光明媚。"
2.  **李四**: (发了一张公园里开满鲜花的图片)
3.  **你**: "@机器人 你有什么建议吗？"

AI收到的“超级问题”会包含：“**现在 你...发了一个消息**: 你有什么建议吗？”

> **AI回复**: “这么好的天气，大家可以去李四发的那个公园散散步...”

#### 场景二：机器人主动发言

假设一个“定时播报”插件在晚上10点需要主动发言，它只想让LLM生成一句“夜深了，大家早点休息”的问候。

1.  *(群里在讨论游戏)*
2.  **玩家A**: "这个BOSS太难了，卡了我一天！"
3.  *(晚上10点到了，定时插件触发)*

定时插件向LLM发起的原始请求可能只是 `说一句晚安问候`。

**有了本插件**，AI实际收到的“超级问题”会是：

```
你正在浏览聊天软件，查看群聊消息。

最近的聊天记录:
玩家A: 这个BOSS太难了，卡了我一天！

... (其他聊天记录) ...

你需要根据以上聊天记录，主动就以下内容发表观点: 说一句晚安问候
... (结尾引导语) ...
```

> **AI的智能回复**: 它看到了大家在聊游戏，于是回复不再是干巴巴的“请早点休息”，而可能是：“夜深了，那位还在攻克BOSS的玩家也早点休息吧，明天再战！大家晚安。”

这就是插件的全部工作流程和核心价值。它通过**全局增强输入**，来**优化所有场景下的AI最终输出**。